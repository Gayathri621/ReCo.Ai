<!DOCTYPE html>
<html lang="en">
  <head>
    <title>ReCo.Ai</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Poppins:200,300,400,700,900"> 
    <link rel="stylesheet" href="css/fonts/icomoon/style.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/magnific-popup.css">
    <link rel="stylesheet" href="css/jquery-ui.css">
    <link rel="stylesheet" href="css/owl.carousel.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mediaelement@4.2.7/build/mediaelementplayer.min.css">


    <link rel="stylesheet" href="css/aos.css">

    <link rel="stylesheet" href="css/style.css">
    
  </head>
  <body>
  
  <div class="site-wrap">

    <div class="site-mobile-menu">
      <div class="site-mobile-menu-header">
        <div class="site-mobile-menu-close mt-3">
          <span class="icon-close2 js-menu-toggle"></span>
        </div>
      </div>
      <div class="site-mobile-menu-body"></div>
    </div>


    <header class="site-navbar py-4" role="banner">

      <div class="container">
        <div class="row align-items-center">


          <div class="col-3">
            <h1 class="site-logo"><a href="index.html" class="h2">
              <img src="./images/reco full.png" alt="" width="50%"></a></h1>
          </div>
          <div class="col-9">
            <nav class="site-navigation position-relative text-right text-md-right" role="navigation">



              <div class="d-block d-lg-none ml-md-0 mr-auto"><a href="#" class="site-menu-toggle js-menu-toggle text-black"><span class="icon-menu h3"></span></a></div>

              <ul class="site-menu js-clone-nav d-none d-lg-block">
                <li class="active">
                  <a href="index.html">Home</a>
                </li>
                <li><a href="about.html">About</a></li>
              </ul>
            </nav>


          </div>

        </div>
      </div>
      
    </header>

    <div class="site-blocks-cover inner-page-cover bg-light mb-5">
      <div class="container" data-aos="zoom-in">
        <div class="row align-items-center">
          <div class="col-12 text-center">
            <h1 class="mb-0">Get to know How it works</h1>
          </div>
        </div>
      </div>
    </div>
    
    <div class="site-section pt-3">
      <div class="container">
        <div class="row mb-5" data-aos="fade-up">
          <div class="col-12">
            <h2 class="display-5 mb-3 text-black">ABSTRACT </h2>
          </div>
          <div class="col-lg-12">
            <p>Mobile phones or smartphones have seen a gradual surge in becoming the central communication device in people’s lives. These tiny technological mastery, equipped with a set of sensors have an ability to simultaneously function as a platform for human activity recognition. The embedded sensors such as the accelerometer, digital compass, gyroscope, GPS and camera are enabling applications spanning across various domains. These sensors pave way to easier and accessible human activity recognition
              With such capabilities, the smartphones have immense applications in healthcare. Smart environments can be developed to provide support to people with risk factors when it comes to living independently.
              We propose a categorization of 6 human activities: walking, walking upstairs, walking downstairs, sitting, standing, laying. We divide this into two large categories: Static( standing, sitting, laying) and Dynamic( Walking, walking upstairs, walking downstairs). We classify the activities performed by the person using the sensor data and report the results,challenges and project prospects.
              
            </p>  
            </div>
          
        </div>




        <div class="row mb-5" data-aos="fade-up">
          <div class="col-12">
            <h2 class="display-5 mb-3 text-black">TARGET AUDIENCE</h2>
          </div>
          <div class="col-lg-12">
            <p> The application targets people who need monitoring and help with their daily activities,especially those with loss of cognitive autonomy. It aims on determining the activities of the person based on sensor data. 
              The primary implementation of the application is in healthcare,especially for monitoring people undergoing physiotherapy, physical trauma recovery and the elderly. 
              </p>
          </div>
          
        </div>



        <div class="row mb-5" data-aos="fade-up">
          <div class="col-12">
            <h2 class="display-5 mb-3 text-black">DATASET</h2>
          </div>
          <div class="col-lg-12">
            <p>
              The dataset used was the Human Activity Recognition Using Smartphones Data Set.

Description:
The data was obtained by carrying out experiments on a group of 30 people within the ages of 19-48 years.The activities performed were :walking,walking upstairs, walking downstairs,sitting,standing,laying.
The data was obtained by wearing a smartphone on the waist. The embedded accelerometer and gyroscope were used to capture linear acceleration and angular velocity for all the 3 axes at a rate of 50Hz.

Attributes:
For each record in the dataset it is provided:
Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.
Triaxial Angular velocity from the gyroscope.
A 561-feature vector with time and frequency domain variables.
Its activity label.
An identifier of the subject who carried out the experiment.
Sensor readings:
Accelerometer and Gyroscope readings

            </p>
          </div>
          
        </div>




        <div class="row mb-5" data-aos="fade-up">
          <div class="col-12">
            <h2 class="display-5 mb-3 text-black">SUGGESTED SKELETAL ARCHITECTURE</h2>
          </div>
          <div class="col-lg-12">
            <p>Activity recognition systems have three main components:
              A low-level sensing module that continuously gathers relevant information about activities using microphones, accelerometers, light sensors, and so on
             A feature processing and selection module that processes the raw sensor data into features that help discriminate between activities 
              A classification module that uses the features to infer what activity an individual or group of individuals is engaged
             
            </p></div>
          
        </div>




        <div class="row mb-5" data-aos="fade-up">
          <div class="col-12">
            <h2 class="display-5 mb-3 text-black">MODEL:</h2>
          </div>
          <div class="col-lg-12">
            <p>
              The basic model principle applied here are deep learning networks with LSTM as their foundational functionalities. The model has been implemented via the latest version of Keras (Keras 2.4.2) with a tensorflow backend. The model uses LSTM layers because of two main reasons: 
To avoid vanishing and exploding gradients
To make best learning sense out of incomprehensible and noisy data
The dataset used here is huge and has noisy values, LSTM proves to be the best model by eradicating the complete need to go through the noisy data and undergo noise attenuation manually. As the data is also huge the gradient descent method usually undergoes vanishing or exploding gradients which is managed by LSTM as well.
Architecture:
The model’s data is using a mini batch of size 16 and is trained over 30 epochs. It contains 32 hidden layers of tan-h LSTM. A dropout layer of 0.5 parameter is passed to reduce the risk of overfitting. The architecture ends with a dense layer with an activation function of sigmoid.
As the classification is multiclass, hence, the loss used is categorical cross entropy. The model is evaluated over the ‘rmsprop’ function and measured over ‘accuracy’ metrics.
An input dimension of 9 parameters accreted with 32 LSTM layers form a recondite convoluted learning network, which ends in a dense connected layer to bring out all the possible combinations of nodes for the module.

            </p>
          </div>
          
        </div>



        <div class="row mb-5" data-aos="fade-up">
          <div class="col-12">
            <h2 class="display-5 mb-3 text-black">CHALLENGES
            </h2>
          </div>
          <div class="col-lg-12">
            <p>Intraclass variation and interclass similarity
              Recognition under real world settings viz. Complex environmental factors,multiple subjects
              Data Security
              Availability of technology 
              Scalability
              Adaptability
              
             
            </p></div>
          
        </div>


        <div class="row mb-5" data-aos="fade-up">
          <div class="col-12">
            <h2 class="display-5 mb-3 text-black">PROJECT PROSPECTS

            </h2>
          </div>
          <div class="col-lg-12">
            <p>Ambient Assisted Living
              Ambient Assisted Living (AAL) environments encompass technical systems and the Internet of Things (IoT) tools to support seniors in their daily routines. They aim to enable seniors to live independently and safely for as long as possible when faced declining physical or cognitive capacities.
              The demarcation between traditional and smart systems is  automation. A vast number of existing commercial projects are based on predefined rules and actions,which can be changed manually,thereby reducing efficiency. By integrating IOT and Artificial Intelligence,we get a futuristic amalgamation:Ambient Intelligence which has immense prospects to help the ailing.
              
              Visual human activity recognition 
              Smart environments which include cameras and sensors can be used to obtain images and hence can be used for surveillance and monitoring. This is a viable addition to the project which makes it even serviceable and gives it a commercial use case.
              
              
             
            </p></div>
          
        </div>




      


      
    



        <div class="row mb-5" data-aos="fade-up">
          <div class="col-12">
            <h3 class="display-5 mb-3 text-black">REFERENCES

            </h3>
          </div>
          <div class="col-lg-12">

            <p>
              <a href=" https://github.com/STRCWearlab/DeepConvLSTM">
              https://github.com/STRCWearlab/DeepConvLSTM</a>


              <a href="http://www.mdpi.com/1424-8220/16/1/115/html">
              http://www.mdpi.com/1424-8220/16/1/115/html
            </a>
              
             
            </p></div>
          
        </div>



      </div>
      </div>
    </div>




    
    

   
    
   

    
    <footer class="site-footer">
      <div class="container">

        <div class="row pt-5 mt-5 text-center">
          <div class="col-md-12">
            <p>
              Made with <i class="icon-heart-o" aria-hidden="true"></i> by <a href="" target="_blank" > Team DS Community</a>
              
            </p>
          </div>
          
        </div>
      </div>
    </footer>
  </div>

  <script src="js/jquery-3.3.1.min.js"></script>
  <script src="js/jquery-migrate-3.0.1.min.js"></script>
  <script src="js/jquery-ui.js"></script>
  <script src="js/popper.min.js"></script>
  <script src="js/bootstrap.min.js"></script>
  <script src="js/jquery.stellar.min.js"></script>
  <script src="js/jquery.magnific-popup.min.js"></script>
  <script src="js/aos.js"></script>


  <script src="js/main.js"></script>
    
  </body>
</html>